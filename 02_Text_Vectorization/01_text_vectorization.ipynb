{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# `# Text Vectorization:`\n",
    "\n",
    "- 01: OHE\n",
    "- 02: BoW\n",
    "- 03: Bag of N-gram\n",
    "- 04: Tf-Idf\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# `01 OHE:`\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# `02 BAG OF Words:`\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campusx watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campusx write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  output\n",
       "0   people watch campusx       1\n",
       "1  campusx watch campusx       1\n",
       "2   people write comment       0\n",
       "3  campusx write comment       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame({'text':['people watch campusx','campusx watch campusx','people write comment','campusx write comment'],'output':[1,1,0,0]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 11 stored elements and shape (4, 5)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "bow = cv.fit_transform(df['text'])\n",
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': 2, 'watch': 3, 'campusx': 0, 'write': 4, 'comment': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# vocubabulary:\n",
    "cv.vocabulary_ # 0,1,2,3,4 is the ordering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 1, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# vector of 0th index in df (people watch campusx): \n",
    "# from vocab, if we have, people and it's index 2 that means in array \n",
    "# {0,1,2,3,4}\n",
    "# {0 0 1 0 0 }\n",
    "\n",
    "\n",
    "# so,  (people watch campusx)\n",
    "# {'people': 2, 'watch': 3, 'campusx': 0, 'write': 4, 'comment': 1}\n",
    "# from vocab: 0-> campusx have in our sentence 0th index: 1\n",
    "# from vocab: 1-> commnet haven't in our sentence 1st index: 0\n",
    "# from vocab: 2-> people, have in our sentence 2nd index: 1\n",
    "# from vocab: 3-> watch, have in our sentence 3nd index: 1\n",
    "# from vocab: 4-> write, haven't in our sentence 2nd index: 0\n",
    "\n",
    "bow[0].toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 3 stored elements and shape (1, 5)>\n",
      "  Coords\tValues\n",
      "  (0, 2)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 1)\t1\n",
      "\n",
      "{'people': 2, 'watch': 3, 'campusx': 0, 'write': 4, 'comment': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(bow[2])\n",
    "print()\n",
    "\n",
    "# why toarray() bacuse, sklearn give us sparse matrix we need to convert it to array.\n",
    "print(cv.vocabulary_)\n",
    "bow[1].toarray()\n",
    "# campusx watch campusx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 1, 0, 1, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# bag of words can control OOV:\n",
    "cv.transform([\"campusx watch campusx and  yasin arafat write comment of campusx\"]).toarray()\n",
    "# here, we have \"yasin,arafat and, of\", but don't get `**Out Of Vocavulary Error**`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## #parameter of countvectorizer()\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`1st go to the documentation:`\n",
    "\n",
    "lowercase=True,  \n",
    "preprocessor=None, <br>\n",
    "tokenizer=None, <br>\n",
    "stop_words=None: \n",
    "<br>\n",
    "\n",
    "**We can define our own lowercase,preprocssor,tokenizer and stop_words যেইটা আমরা text preprocessing এ করে থাকি  ।** \n",
    "<br>\n",
    "\n",
    "ngram_range=(1, 1): **We will see this later** <br>\n",
    "binary: true, default: false:  **Used in sentiment analysis:** <br>\n",
    "max_feture: 1,2,3,4: **see note**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 2, 'watch': 3, 'campusx': 0, 'write': 4, 'comment': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# example of binary: true\n",
    "\n",
    "# if we set binary=ture then if (frequency>1) then value=1:\n",
    "# 1 means words exist \n",
    "# 0 means words is not exist, if binary=True\n",
    "# while doing sentiment analysis it's good\n",
    "\n",
    "cv1 = CountVectorizer(binary=True)\n",
    "cv1.fit_transform(df['text'])\n",
    "print(cv1.vocabulary_)\n",
    "cv1.transform([\"campusx watch campusx and  yasin arafat write comment of campusx\"]).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'campusx': np.int64(0)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# max feature: it takes only the campusx:\n",
    "# by using this we can ignore reare words when we will work on a big dataset\n",
    "\n",
    "cv1 = CountVectorizer(binary=True,max_features=1)\n",
    "cv1.fit_transform(df['text'])\n",
    "print(cv1.vocabulary_)\n",
    "cv1.transform([\"campusx watch campusx and  yasin arafat write comment of campusx\"]).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# `03 BAG OF N-Gram:`\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people watch campusx\n",
      "{'people watch': 2, 'watch campusx': 4, 'campusx watch': 0, 'people write': 3, 'write comment': 5, 'campusx write': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# bigram:\n",
    "cv3 = CountVectorizer(ngram_range=(2,2)) \n",
    "bow = cv3.fit_transform(df['text'])\n",
    "print(df['text'][0])\n",
    "print(cv3.vocabulary_)\n",
    "bow[0].toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people watch campusx\n",
      "{'people': 4, 'watch': 7, 'campusx': 0, 'people watch': 5, 'watch campusx': 8, 'campusx watch': 1, 'write': 9, 'comment': 3, 'people write': 6, 'write comment': 10, 'campusx write': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# unigram+bigram\n",
    "cv3 = CountVectorizer(ngram_range=(1,2))\n",
    "bow = cv3.fit_transform(df['text'])\n",
    "print(df['text'][0])\n",
    "print(cv3.vocabulary_)\n",
    "bow[0].toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(cv3.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# `#04 Tf-Idf:`\n",
    "\n",
    "<br>\n",
    "\n",
    "**See the documentation.**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49681612, 0.        , 0.61366674, 0.61366674, 0.        ],\n",
       "       [0.8508161 , 0.        , 0.        , 0.52546357, 0.        ],\n",
       "       [0.        , 0.57735027, 0.57735027, 0.        , 0.57735027],\n",
       "       [0.49681612, 0.61366674, 0.        , 0.        , 0.61366674]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# tf-idf value for the documents:\n",
    "tfidf.fit_transform(raw_documents=df['text']).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['campusx' 'comment' 'people' 'watch' 'write']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.22314355, 1.51082562, 1.51082562, 1.51082562, 1.51082562])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Calcuation of idf: in sklearn they add+1: \n",
    "print(tfidf.get_feature_names_out())\n",
    "tfidf.idf_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
